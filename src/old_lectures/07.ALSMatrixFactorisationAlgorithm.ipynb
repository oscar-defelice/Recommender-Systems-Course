{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Recommender Systems\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img width=\"721\" alt=\"cover-image\" src=\"https://user-images.githubusercontent.com/49638680/204351915-373011d3-75ac-4e21-a6df-99cd1c552f2c.png\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "# Matrix Factorisation\n",
    "\n",
    "The __Alternating Least Squares__ algorithm is a popular technique used in recommender systems for collaborative filtering. \n",
    "As you might remember, collaborative filtering is a technique that uses the past behaviour of users to make recommendations for new items. \n",
    "The goal of the ALS algorithm is to factorise a user-item matrix into two matrices, one representing the users and the other representing the items, so that the dot product of the two matrices approximates the original matrix.\n",
    "\n",
    "The ALS algorithm works by alternately fixing one of the matrices while optimising the other. \n",
    "Specifically, it alternates between fixing the user matrix and optimising the item matrix and fixing the item matrix and optimising the user matrix. This alternating process continues until a certain convergence criteria is met.\n",
    "\n",
    "The optimisation process involves minimising the difference between the predicted ratings and the actual ratings in the user-item matrix. This is done by computing the _least squares_ solution for each matrix. The algorithm uses a regularization term to prevent overfitting and ensure that the solution is stable.\n",
    "\n",
    "The ALS algorithm can handle large and sparse datasets by breaking down the computation into smaller sub-problems. This allows the algorithm to scale to millions of users and items. The algorithm can also handle implicit feedback data where the absence of a rating is not necessarily a negative signal.\n",
    "\n",
    "A further advantage of the ALS algorithm is that it is computationally efficient and can be parallelized easily. This makes it suitable for large-scale recommender systems used by companies such as Amazon and Netflix. The algorithm is also robust to noise and can handle missing data.\n",
    "\n",
    "However, one limitation of the ALS algorithm is that it assumes that the user-item matrix can be factorised into two matrices. This assumption may not hold in some cases, leading to poor recommendations. Additionally, the ALS algorithm may not perform well in situations where there are few ratings for each user or item.\n",
    "\n",
    "In conclusion, the ALS algorithm is a widely used technique in collaborative filtering-based recommender systems. It is computationally efficient, scalable, and can handle large and sparse datasets. However, it may not perform well in all situations and its assumptions may not hold in some cases.\n",
    "\n",
    "## A common problem \n",
    "\n",
    "In all the algorithms for recommender systems we have seen up to this point, we could find some common issues:\n",
    "\n",
    "1. _Popularity bias_: recommendations were imbalanced towards the most \"popular\" items, the ones with a great number of ratings. In general, this refers to system recommends the movies with the most interactions without any personalisation.\n",
    "2. _Cold start_: recommendations for users, items or both with a low number of ratings were not really accurate. In general, this refers to when movies added to the catalogue have either none or very little interactions while recommender rely on the movieâ€™s interactions to make recommendations.\n",
    "3. _Scalability issue_: if the underlying training database is too large, we would struggle to fit our model. In generale, this refers to the lack of ability to scale to much larger sets of data when more and more users and movies got added into our database.\n",
    "\n",
    "All the three above are very typical challenges for collaborative filtering recommender. \n",
    "\n",
    "They arrive naturally along with the user-movie (or movie-user) interaction matrix where each entry records an interaction of a user $i$ and a movie $j$. In a real world setting, the vast majority of movies receive very few or even no ratings at all by users. We are looking at an extremely sparse matrix with more than $99\\%$ of entries are missing values.\n",
    "\n",
    "With such a sparse matrix, what ML algorithm can be trained and reliable to make inference? \n",
    "\n",
    "To find solutions to the question, we are effectively solving a data sparsity problem.\n",
    "\n",
    "## Matrix Factorization\n",
    "\n",
    "In collaborative filtering, matrix factorisation is the state-of-the-art solution for sparse data problem, although it has become widely known since [Netflix Prize Challenge](https://www.netflixprize.com/).\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img width=\"650\" src=\"https://i0.wp.com/softwareengineeringdaily.com/wp-content/uploads/2018/10/image3-1.png?resize=975%2C597&ssl=1\">\n",
    "</p>\n",
    "\n",
    "Matrix factorisation is a family of mathematical operations for matrices in linear algebra. \n",
    "\n",
    "To be specific, a matrix factorisation is a decomposition of a matrix $A$ into a product of matrices $B, C$ of suitable dimensions.\n",
    "\n",
    "$$ A \\simeq B \\times C \\, .$$ \n",
    "\n",
    "In the case of collaborative filtering, matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices. \n",
    "One matrix can be seen as the user matrix where rows represent users and columns are latent factors. \n",
    "The other matrix is the item matrix where rows are latent factors and columns represent items.\n",
    "\n",
    "### How does matrix factorisation solve our problems?\n",
    "\n",
    "There are several aspects of matrix factorisation that can be exploited to solve the issues described above.\n",
    "\n",
    "1. The matrix factorisation-based model learns the user-item interaction matrix factorisation by user and item representation matrices. This allows the model to predict better personalised movie ratings for users. (Addresses Popularity bias and cold start)\n",
    "\n",
    "2. With matrix factorisation, less-known items can have the same rich latent representation of \"popular\" ones. This improves recommender's ability to suggest less-known movies. (Addresses Popularity bias)\n",
    "\n",
    "3. Matrix factorisation algorithm is really efficient at prediction time, since it is just a matter of multiplying two matrices. (Addresses scalability issue)\n",
    "\n",
    "4. The matrix factorisation algorithm is parallelisable. (Addresses scalability issue)\n",
    "\n",
    "## Alternating Least Squares\n",
    "\n",
    "We have already seen how FunkSVD can be used to factorise the matrix of ratings into tow pieces that can be interpreted as users and items features.\n",
    "\n",
    "FunkSVD and ALS are both matrix factorisation algorithms used for collaborative filtering in recommendation systems. However, they use different approaches to factorise the original ratings matrix into two low-rank matrices representing users and items.\n",
    "\n",
    "As exposed previously, FunkSVD minimises the squared error between the original ratings matrix and the reconstructed matrix as a sum of element-wise squared differences. It updates the user and item matrices using gradient descent to minimize this objective function. The algorithm works by computing the difference between the ratings matrix and the dot product of user and item matrices, then computing the gradient of the objective function with respect to each matrix, and updating the matrices accordingly. This process is repeated for a fixed number of iterations until convergence.\n",
    "\n",
    "On the other hand, __ALS__ (__Alternating Least Squares__) algorithm aims to minimise the same squared error objective function as FunkSVD but approaches the minimisation problem using an alternating least squares method. The algorithm works by first fixing the user matrix and minimising the objective function with respect to the item matrix, then fixing the item matrix and minimising the objective function with respect to the user matrix. This process is repeated until convergence. In each iteration, the algorithm solves a least squares problem to update the user or item matrix.\n",
    "\n",
    "Mathematically, if $Y$ is the ratings matrix, $\\mathcal{H}_u$ is the user matrix, and $\\mathcal{H}_m$ is the item matrix, then FunkSVD solves the following optimization problem:\n",
    "\n",
    "$$\\underset{\\mathcal{H}_u,\\mathcal{H}_m}{\\mathrm{argmin}} \\sum_{ij}(y_{ij} - \\mathcal{H}_{u,i} \\cdot \\mathcal{H}_{m,j})^2 \\, .$$\n",
    "\n",
    "whereas ALS alternatively solves the following two least squares problems:\n",
    "\n",
    "$$\\mathcal{H}_u = \\underset{\\mathcal{H}_u}{\\mathrm{argmin}} \\sum_{ij}(y_{ij} - \\mathcal{H}_{u,i} \\cdot \\mathcal{H}_{m,j})^2  \\, ,$$\n",
    "\n",
    "$$\\mathcal{H}_m = \\underset{\\mathcal{H}_,}{\\mathrm{argmin}} \\sum_{ij}(y_{ij} - \\mathcal{H}_{u,i} \\cdot \\mathcal{H}_{m,j})^2  \\, .$$\n",
    "\n",
    "where $\\mathcal{H}_u$ and $\\mathcal{H}_m$ are updated alternatively until convergence.\n",
    "\n",
    "A simple introduction to the subject can be found in [this nice blog post](https://sophwats.github.io/2018-04-05-gentle-als.html).\n",
    "\n",
    "## Apache Spark\n",
    "\n",
    "Apache Spark is an open-source, distributed computing system that allows processing large-scale data sets in parallel across a cluster of computers. It provides an interface for programming entire clusters with implicit data parallelism and fault tolerance.\n",
    "\n",
    "Apache Spark is convenient for large datasets because it can handle big data processing in a fast, distributed, and fault-tolerant way. It enables users to process data in parallel across a cluster of machines, which allows for faster processing times. Additionally, Apache Spark can handle various types of data, including structured, semi-structured, and unstructured data, which makes it a versatile tool for data processing.\n",
    "\n",
    "Apache Spark is designed to operate in-memory, meaning that it can keep the data in memory, rather than constantly writing to disk, which results in faster processing times. This in-memory processing feature, combined with the distributed nature of Spark, makes it a convenient tool for handling large datasets.\n",
    "\n",
    "### Terminologies\n",
    "\n",
    "There are certain terminologies which needs to be understood before moving forward.\n",
    "\n",
    "* __Apache Spark__: Apache Spark is an open-source distributed general-purpose cluster-computing framework.It can be used with Hadoop too.\n",
    "* __Collaborative filtering__: Collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users. Consider example if a person A likes item 1, 2, 3 and B like 2,3,4 then they have similar interests and A should like item 4 and B should like item 1.\n",
    "* __Alternating least square (ALS) matrix factorisation__: The idea is basically to take a large (or potentially huge) matrix and factor it into some smaller representation of the original matrix through alternating least squares. We end up with two or more lower dimensional matrices whose product equals the original one. ALS comes in-built in Apache Spark.\n",
    "* __PySpark__: PySpark is the collaboration of Apache Spark and Python. PySpark is the Python API for Spark. It allows Python programmers to harness the power of Spark for big data processing.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Here we are going to implement a simple recommendation system using PySpark. \n",
    "With no further ado, let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Set plot parameters\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 13)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use Spark, we need to initialise a Spark session. We can do this by using the `SparkSession` builder. We can also set the name of the application and the master URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/24 15:28:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ALSMatrixFactorisation\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a `SparkSession` object which is the entry point to programming Spark with the Dataset and DataFrame API.\n",
    "\n",
    "Now we want to load data into Spark. We can do this by using the `read` method of the `SparkSession` object. We can also specify the format of the data. In our case, we are using a json file, so we specify the format as `json`.\n",
    "\n",
    "In this lecture we are going to use data from the Amazon review dataset, in particular, we will focus on musical instruments reviews. The dataset contains 1,790,738 reviews and 1,189,782 users. The dataset is available on [Kaggle](https://www.kaggle.com/eswarchandt/amazon-music-reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|1384719342|  [0, 0]|    5.0|Not much to write...|02 28, 2014|A2IBPI20UZIR0U|cassandra tu \"Yea...|                good|    1393545600|\n",
      "|1384719342|[13, 14]|    5.0|The product does ...|03 16, 2013|A14VAT5EAX3D9S|                Jake|                Jake|    1363392000|\n",
      "|1384719342|  [1, 1]|    5.0|The primary job o...|08 28, 2013|A195EZSQDW3E21|Rick Bennette \"Ri...|It Does The Job Well|    1377648000|\n",
      "|1384719342|  [0, 0]|    5.0|Nice windscreen p...|02 14, 2014|A2C00NNG1ZQQG2|RustyBill \"Sunday...|GOOD WINDSCREEN F...|    1392336000|\n",
      "|1384719342|  [0, 0]|    5.0|This pop filter i...|02 21, 2014| A94QU4C90B1AX|       SEAN MASLANKA|No more pops when...|    1392940800|\n",
      "|B00004Y2UT|  [0, 0]|    5.0|So good that I bo...|12 21, 2012|A2A039TZMZHH9Y| Bill Lewey \"blewey\"|      The Best Cable|    1356048000|\n",
      "|B00004Y2UT|  [0, 0]|    5.0|I have used monst...|01 19, 2014|A1UPZM995ZAH90|               Brian|Monster Standard ...|    1390089600|\n",
      "|B00004Y2UT|  [0, 0]|    3.0|I now use this ca...|11 16, 2012| AJNFQI3YR6XJ5|   Fender Guy \"Rick\"|Didn't fit my 199...|    1353024000|\n",
      "|B00004Y2UT|  [0, 0]|    5.0|Perfect for my Ep...| 07 6, 2008|A3M1PLEYNDEYO8|     G. Thomas \"Tom\"|         Great cable|    1215302400|\n",
      "|B00004Y2UT|  [0, 0]|    5.0|Monster makes the...| 01 8, 2014| AMNTZU1YQN1TH|         Kurt Robair|Best Instrument C...|    1389139200|\n",
      "|B00004Y2UT|  [6, 6]|    5.0|Monster makes a w...|04 19, 2012|A2NYK9KWFMJV4Y|Mike Tarrani \"Jaz...|One of the best i...|    1334793600|\n",
      "|B00005ML71|  [0, 0]|    4.0|I got it to have ...|04 22, 2014|A35QFQI0M46LWO|       Christopher C|It works great bu...|    1398124800|\n",
      "|B00005ML71|  [0, 0]|    3.0|If you are not us...|11 17, 2013|A2NIT6BKW11XJQ|                 Jai|HAS TO GET USE TO...|    1384646400|\n",
      "|B00005ML71|  [0, 0]|    5.0|I love it, I used...|06 16, 2013|A1C0O09LOLVI39|             Michael|             awesome|    1371340800|\n",
      "|B00005ML71|  [0, 0]|    5.0|I bought this to ...|12 31, 2012|A17SLR18TUMULM|         Straydogger|           It works!|    1356912000|\n",
      "|B00005ML71|  [0, 0]|    2.0|I bought this to ...|08 17, 2013|A2PD27UKAD3Q00|Wilhelmina Zeitge...|Definitely Not Fo...|    1376697600|\n",
      "|B000068NSX|  [0, 0]|    4.0|This Fender cable...|08 13, 2013| AKSFZ4G1AXYFC|        C.E. \"Frank\"|Durable Instrumen...|    1376352000|\n",
      "|B000068NSX|  [0, 0]|    5.0|wanted it just on...| 07 9, 2013| A67OJZLHBBUQ9|Charles F. Marks ...|fender 18 ft. Cal...|    1373328000|\n",
      "|B000068NSX|  [3, 3]|    5.0|I've been using t...|03 18, 2013|A2EZWZ8MBEDOLN|              Charlo|So far so good.  ...|    1363564800|\n",
      "|B000068NSX|  [0, 0]|    5.0|Fender cords look...| 08 7, 2013|A1CL807EOUPVP1|             GunHawk|Add California to...|    1375833600|\n",
      "|B000068NSX|  [0, 0]|    4.0|This is a cool lo...|03 16, 2012|A1GMWTGXW682GB|            MetalFan|Cheap and cool lo...|    1331856000|\n",
      "|B000068NSX|  [0, 0]|    5.0|The Fender 18 Fee...|01 29, 2014|A2G12DY50U700V|         Ricky Shows|Fender 18 Feet Ca...|    1390953600|\n",
      "|B000068NSX|  [0, 0]|    4.0|Very good cable. ...| 12 8, 2012| A3E0CF25A7LD2|              WBowie|        Guitar Cable|    1354924800|\n",
      "|B000068NTU|  [0, 0]|    5.0|Got this cable to...| 07 5, 2012|A2W3CLAYZLDPTV|Amazon Customer \"...|      Quality cable!|    1341446400|\n",
      "|B000068NTU|  [0, 0]|    5.0|When I was search...|10 31, 2013|A398X9POBHK69N|     Ann Vande Zande|I Got Great Prici...|    1383177600|\n",
      "|B000068NTU|  [0, 0]|    4.0|Cant go wrong. Gr...| 07 3, 2013| AXWB93VKVML6K|      Michael Hassey|          Its a Hosa|    1372809600|\n",
      "|B000068NTU|  [0, 0]|    5.0|The ends of the m...|01 25, 2012|A2FZ4Z0UFA1OR8|                 Pat|  Quality and Secure|    1327449600|\n",
      "|B000068NTU|  [0, 0]|    5.0|Just trying to fi...|10 15, 2013| AXP9CF1UTFRSU|                tada|        Midi to Midi|    1381795200|\n",
      "|B000068NVI|  [1, 1]|    4.0|The Hosa XLR cabl...|07 11, 2012|A2CCGGDGZ694CT|            b carney|Very Heavy Cables...|    1341964800|\n",
      "|B000068NVI|  [0, 0]|    5.0|I bought these to...|02 19, 2014|A27DR1VO079F1V|           Dan Edman|         Still going|    1392768000|\n",
      "|B000068NVI|  [0, 0]|    5.0|Sturdy cord and p...|05 26, 2012|A1LQC225SE8UNI|         David Burch|Does what it's su...|    1337990400|\n",
      "|B000068NVI|  [0, 0]|    5.0|Use it every week...|08 10, 2013| AU9BPT3Y3K6J4|         G. L. Beebe|          Good cable|    1376092800|\n",
      "|B000068NVI|  [0, 0]|    4.0|Hosa products are...|03 11, 2014|A14Z9LAETO21KL|           Gutjammer|         Good Enough|    1394496000|\n",
      "|B000068NVI|  [0, 0]|    5.0|This was exactly ...|09 16, 2013|A2074KEJGRYJV4|              hcross|   Great little cord|    1379289600|\n",
      "|B000068NVI|  [0, 0]|    5.0|I bought these be...| 01 6, 2012| A7TRK2GG6BHWD|Johnny Pasta \"Joh...|Does the job. Wha...|    1325808000|\n",
      "|B000068NVI|  [0, 0]|    4.0|This cable seems ...|02 12, 2012|A319B090A2POEB|                 Lee|    Decent mic cable|    1329004800|\n",
      "|B000068NVI|  [0, 0]|    4.0|These are not the...|09 16, 2013|A396ELNTQDFYPO|           Mark King|Decent inexpensiv...|    1379289600|\n",
      "|B000068NVI|  [0, 0]|    4.0|This is a fine ca...|12 15, 2013|A17CU1D2CWXOHB|                Rick|       a fine cable.|    1387065600|\n",
      "|B000068NVI|  [0, 0]|    5.0|I've used a lot o...|09 17, 2013|A1S0HTDO0P4N5V|R. Wristen \"The P...|    Hosa is the best|    1379376000|\n",
      "|B000068NVI|  [0, 0]|    4.0|I bought this cor...|12 14, 2012|A3DWQW2L39RB1S|            S. Dawdy|Excellent quality...|    1355443200|\n",
      "|B000068NVI|  [0, 0]|    5.0|Nice solid cables...|06 29, 2013| AQQ91U1U4YKDF| Vince Lewis \"Vince\"|         great value|    1372464000|\n",
      "|B000068NW5|  [0, 0]|    5.0|Good quality cabl...|07 15, 2014| AA5TINW2RJ195|                null|          Five Stars|    1405382400|\n",
      "|B000068NW5|  [0, 0]|    5.0|Zero issues with ...|03 31, 2012| ABC68JUCPTVOE| A. Fabbri \"afabbri\"|Pretty cheap cabl...|    1333152000|\n",
      "|B000068NW5|  [0, 0]|    5.0|Realtively inexpe...|05 28, 2014|A3W2E6S24BTXXK|    airchamp \"ariel\"|     very nice cable|    1401235200|\n",
      "|B000068NW5|  [0, 0]|    5.0|I bought this bec...|03 13, 2013|A3872Y2XH0YDX1|     Amazon Customer|Nice guitar cable...|    1363132800|\n",
      "|B000068NW5|  [0, 0]|    4.0|This is a very ni...| 01 6, 2014|A398X9POBHK69N|     Ann Vande Zande|  Does What You Want|    1388966400|\n",
      "|B000068NW5|[12, 13]|    4.0|Cheap and good te...|11 18, 2010|A13A81NN0NRD1S|aspiring saint \"T...|flexible, soft ru...|    1290038400|\n",
      "|B000068NW5|  [0, 0]|    5.0|Seems sturdy enou...|06 27, 2013|A1EUO0BU72JR7T|               Bilbo|Works wonderfully...|    1372291200|\n",
      "|B000068NW5|  [0, 0]|    5.0|I'm not a profess...|01 30, 2013|A1H4WSC8JWS59N|             bradley|           excellent|    1359504000|\n",
      "|B000068NW5|  [0, 1]|    5.0|This Hosa Cable i...| 09 5, 2012|A3OXHLG6DIBRW8|       C. Hill \"CFH\"|Great Guitar Cabl...|    1346803200|\n",
      "|B000068NW5|  [2, 2]|    2.0|I didn't expect t...| 07 6, 2011|A12ABV9NU02O29|            C. Longo|    Cannot recommend|    1309910400|\n",
      "|B000068NW5|  [0, 0]|    5.0|Bought this for m...| 03 5, 2014|A2U1Z3TZ4P76JB|            C. Zemer|Cable works as de...|    1393977600|\n",
      "|B000068NW5|  [0, 0]|    1.0|It hums, crackles...| 02 9, 2014|A1L7M2JXN4EZCR|             David G|I have bought man...|    1391904000|\n",
      "|B000068NW5|  [0, 0]|    4.0|I am not hard on ...| 06 8, 2013|A37A41GWQFMK3D|           Dr. Freud|   gets the job done|    1370649600|\n",
      "|B000068NW5|  [0, 0]|    5.0|I have found Hosa...|05 13, 2014|A2JK2ITE138P7Z|            Dr. Marc|Nice cable for th...|    1399939200|\n",
      "|B000068NW5|  [0, 0]|    5.0|This is good cabl...| 10 8, 2013|A1DVUFG2QSJ6IK|     grandpa \"Randy\"|Well made audio c...|    1381190400|\n",
      "|B000068NW5|  [0, 0]|    5.0|Pretty crappy cab...|07 25, 2013|A34VZEFXQJJ7AT|          Guitarslim|                  Eh|    1374710400|\n",
      "|B000068NW5|  [0, 0]|    5.0|I use this cord i...|02 12, 2014|A1SD1C8XK3Z3V1|guitfiddleblue \"g...|great, affordable...|    1392163200|\n",
      "|B000068NW5|  [0, 0]|    4.0|This my second Ho...|04 18, 2014| AKHWZ3S1UVZAO|        Hagen LeBray|          Nice Cable|    1397779200|\n",
      "|B000068NW5|  [0, 0]|    3.0|Works for practic...| 07 5, 2014|A3LNNEYLGGCO25|              Hans R|maybe not the bes...|    1404518400|\n",
      "|B000068NW5|  [0, 0]|    5.0|These cables have...|01 24, 2014| AMACM7BGUQCZD|              IBZANE|High quality low ...|    1390521600|\n",
      "|B000068NW5|  [0, 0]|    5.0|In my opinion it ...|01 13, 2014|A38HMS5RYSYF8G|   James I Van Asten|works as advertis...|    1389571200|\n",
      "|B000068NW5|  [0, 0]|    5.0|Hosa guitar cable...|07 23, 2012| A6D91KPQGIDKZ|  Jim R. \"Photo man\"|         Good cables|    1343001600|\n",
      "|B000068NW5|  [0, 0]|    5.0|This product does...|08 25, 2013|A2RCCN4KEXZGC8|Joe Average \"Joe ...|       No Complaints|    1377388800|\n",
      "|B000068NW5|  [0, 0]|    5.0|Good quality guit...| 07 6, 2013|A3GAP455S8YH0M|Joe's Gadgets \"JO...|        Good Quality|    1373068800|\n",
      "|B000068NW5|  [0, 0]|    5.0|This is a good so...| 02 3, 2014|A1N06X05VZWO5Y|          Joe Toland|Perfect for pract...|    1391385600|\n",
      "|B000068NW5|  [3, 3]|    5.0|This guitar cable...|12 29, 2010|A3TA1UJWRJF9NC|       jschristian44|Nice high quality...|    1293580800|\n",
      "|B000068NW5|  [0, 0]|    4.0|Good product at a...|01 25, 2013|A3VPISTBNS66C5|            k2review|          Works well|    1359072000|\n",
      "|B000068NW5|  [0, 0]|    5.0|This item is well...|07 15, 2013|A1E5FQZTUM8OC1|             Kenwood|    Well built cable|    1373846400|\n",
      "|B000068NW5|  [0, 0]|    5.0|This amp plug is ...|08 29, 2013|A3MYWHYZ30WLQJ|             kyle c.|pperfect amp chor...|    1377734400|\n",
      "|B000068NW5|  [0, 0]|    5.0|Hosa Cable GTR210...| 02 4, 2013|A1FHOW9NVOH8XR|                 Lee|Hosa Cable GTR210...|    1359936000|\n",
      "|B000068NW5|  [0, 0]|    3.0|...unbalanced gui...|02 12, 2012|A319B090A2POEB|                 Lee|Standard guitar c...|    1329004800|\n",
      "|B000068NW5|  [0, 0]|    5.0|This is your basi...|01 16, 2014|A2VH0UT5EQFB6P|          Loveguitar|Hosa Electric Gui...|    1389830400|\n",
      "|B000068NW5|  [0, 0]|    4.0|Hosa cable qualit...|01 21, 2013|A396ELNTQDFYPO|           Mark King|      So Far So Good|    1358726400|\n",
      "|B000068NW5|  [0, 1]|    3.0|It's a cable, no ...|02 26, 2014|A2WYAHJGST6AOT|                Matt|       average cable|    1393372800|\n",
      "|B000068NW5|  [0, 0]|    5.0|I never really co...| 10 4, 2013| A781ITP3HE2N5|Michael Livote \"d...|Good quality, low...|    1380844800|\n",
      "|B000068NW5|  [2, 2]|    3.0|One end was loose...|06 14, 2013| AN73VQ17FZVJ8|                 MJK|  Good for the Price|    1371168000|\n",
      "|B000068NW5|  [6, 6]|    4.0|For the price, fa...|04 17, 2012| ALUTHT4U058KZ|       M. M. Jackson|Feel a little fli...|    1334620800|\n",
      "|B000068NW5|  [0, 0]|    5.0|Hosa makes good s...|07 10, 2014|A1A15ECLHM9BQY|                Nick|           Excellent|    1404950400|\n",
      "|B000068NW5|  [0, 0]|    4.0|Only complaint is...|06 28, 2014|A1S8R9OAIQT7YI|     patriotsarebest|Only complaint is...|    1403913600|\n",
      "|B000068NW5|  [0, 0]|    5.0|Hard to day too m...|09 23, 2013|A3RHT4KI3H5TVH|                pops|            worth it|    1379894400|\n",
      "|B000068NW5|  [0, 0]|    5.0|For the price, th...| 01 8, 2013| AVY8D3ULJTX0H|          P. Panehal|               Works|    1357603200|\n",
      "|B000068NW5|  [0, 0]|    5.0|This cable dispro...| 11 2, 2011|A15BHBF0L0HV1F|Quaestor \"Raoul D...|Good quality, gre...|    1320192000|\n",
      "|B000068NW5|  [0, 0]|    5.0|I was looking for...| 11 8, 2013|A1AFN4T80DZ3RR|              Quique|Very good quality...|    1383868800|\n",
      "|B000068NW5|  [0, 0]|    5.0|These are Good ca...|05 22, 2013| A3DCG2MNPR4BW|        RAYON ORMOND|Good cables at a ...|    1369180800|\n",
      "|B000068NW5|  [0, 0]|    5.0|very sturdy, high...|06 16, 2014|A3NGAQKJ6X088B|R. Beckmeyer \"Pos...|works well, great...|    1402876800|\n",
      "|B000068NW5|  [0, 0]|    5.0|Unless you're goi...| 09 7, 2012|A35XRT4BW4I6UD|   Richard R. Casper|         Great Value|    1346976000|\n",
      "|B000068NW5|  [0, 0]|    5.0|I have many lengt...|10 10, 2013| AKYDGCKCY7H9F|R. W. Milyard \"Ge...|         Good cables|    1381363200|\n",
      "|B000068NW5|  [4, 4]|    4.0|I've been using t...|01 21, 2011|A19NGYCQ1NCF3W|            S. Haney|   Very Solid Cables|    1295568000|\n",
      "|B000068NW5|  [0, 0]|    1.0|I'm a pro-cheapo ...|03 14, 2014|A3UD50M7M72150|        synthezatory|                Crap|    1394755200|\n",
      "|B000068NW5|  [0, 0]|    5.0|Works great on my...| 02 4, 2012|A2B78RXJ2PB6ZD|                 Tom|Works Good. No co...|    1328313600|\n",
      "|B000068NW5|  [0, 0]|    5.0|Good cable, as go...|12 10, 2013|A18RGYRCEN181M|              Truvor|   Good guitar cable|    1386633600|\n",
      "|B000068NW5|  [0, 0]|    5.0|I own lots of hos...|02 15, 2013|A18LZ6VHS4DK69|       Wesley Newell|          hosa rocks|    1360886400|\n",
      "|B000068NZC|  [0, 0]|    3.0|It is a decent ca...|03 26, 2014| AQG6AQXC703WD|                 Bob|        Does Its Job|    1395792000|\n",
      "|B000068NZC|  [0, 0]|    5.0|the cable is grea...|06 30, 2013|A2YGWCX3DQ6ER0|   Christian Morales|good for direct c...|    1372550400|\n",
      "|B000068NZC|  [3, 3]|    5.0|Bought this to ho...| 12 6, 2011|A21VM9WVF8EOSJ|  J. Warren \"NiALTA\"|Does what it was ...|    1323129600|\n",
      "|B000068NZC|  [3, 3]|    5.0|Just received thi...|04 25, 2012|A3M48SSAOTBSMW|L. Rapoport \"lenr...|   Works as expected|    1335312000|\n",
      "|B000068NZC|  [0, 0]|    4.0|If you're like me...| 04 7, 2014| AFLRU6952DEFX|                  S.|  Good for some uses|    1396828800|\n",
      "|B000068NZC|  [0, 0]|    2.0|I bought this for...|09 16, 2013|A1W3CEEQBJ4GTN|          S. Marchuk|Measure your damn...|    1379289600|\n",
      "|B000068NZC|  [0, 0]|    5.0|Well made, XLR 3 ...|05 26, 2013| AXP9CF1UTFRSU|                tada|           Recommend|    1369526400|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"../data/musicalInstruments/Musical_Instruments_5.json\")\n",
    "df.show(100, truncate=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between Spark Dataframe and Pandas Dataframe\n",
    "\n",
    "Pandas and Spark dataframes are both tabular data structures, but they have some differences in terms of functionality and usage.\n",
    "\n",
    "As known, Pandas is a Python library that provides easy-to-use data structures and data analysis tools. The main data structure in Pandas is the DataFrame, which is a two-dimensional table with rows and columns. Pandas dataframes are stored in memory and can be manipulated using a wide range of functions and methods. Pandas is well-suited for working with datasets that fit into memory on a single machine.\n",
    "\n",
    "On the other hand, Spark is a distributed computing framework that provides an interface for programming cluster computing with a focus on big data processing. Spark provides a distributed data processing framework that can handle large datasets by distributing the data across a cluster of machines. Spark uses a data abstraction called _Resilient Distributed Datasets_ (RDDs) which is a fault-tolerant collection of elements that can be operated on in parallel. Spark's primary data abstraction for structured data processing is the DataFrame. Spark DataFrames are similar to Pandas DataFrames in terms of functionality, but they are distributed across a cluster of machines and stored in a distributed file system like _Hadoop Distributed File System_ (HDFS).\n",
    "\n",
    "To sum up, some key differences between Pandas and Spark dataframes are:\n",
    "\n",
    "1. **Data size**: Pandas is designed to handle datasets that fit into memory on a single machine, while Spark can handle much larger datasets by distributing the data across a cluster of machines.\n",
    "\n",
    "2. **Data processing**: Spark is designed for distributed computing and can process data in parallel across a cluster of machines. Pandas can only process data on a single machine, but it provides a wide range of functions and methods for manipulating data.\n",
    "\n",
    "3. **Data storage**: Pandas dataframes are stored in memory, while Spark dataframes are stored in a distributed file system like HDFS.\n",
    "\n",
    "4. **Performance**: Spark can be faster than Pandas when processing large datasets due to its ability to distribute the computation across a cluster of machines.\n",
    "\n",
    "In summary, Pandas is great for working with small to medium-sized datasets that can fit into memory on a single machine, while Spark is ideal for working with large datasets that require distributed computing across a cluster of machines.\n",
    "\n",
    "Hence, it should be quite clear why we want to model our recommendation system using Spark. We want to be able to handle large datasets, and Spark is the perfect tool for this task.\n",
    "\n",
    "Let's select the appropriate columns from the dataset and filter them from the Spark dataframe.\n",
    "\n",
    "Indeed, we do not need all the columns present in the dataframe. Only `asin` which is ProductID, `reviewerID` and `overall` (the rating given by users to each product) is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-------+\n",
      "|    reviewerID|      asin|overall|\n",
      "+--------------+----------+-------+\n",
      "|A2IBPI20UZIR0U|1384719342|    5.0|\n",
      "|A14VAT5EAX3D9S|1384719342|    5.0|\n",
      "|A195EZSQDW3E21|1384719342|    5.0|\n",
      "|A2C00NNG1ZQQG2|1384719342|    5.0|\n",
      "| A94QU4C90B1AX|1384719342|    5.0|\n",
      "|A2A039TZMZHH9Y|B00004Y2UT|    5.0|\n",
      "|A1UPZM995ZAH90|B00004Y2UT|    5.0|\n",
      "| AJNFQI3YR6XJ5|B00004Y2UT|    3.0|\n",
      "|A3M1PLEYNDEYO8|B00004Y2UT|    5.0|\n",
      "| AMNTZU1YQN1TH|B00004Y2UT|    5.0|\n",
      "|A2NYK9KWFMJV4Y|B00004Y2UT|    5.0|\n",
      "|A35QFQI0M46LWO|B00005ML71|    4.0|\n",
      "|A2NIT6BKW11XJQ|B00005ML71|    3.0|\n",
      "|A1C0O09LOLVI39|B00005ML71|    5.0|\n",
      "|A17SLR18TUMULM|B00005ML71|    5.0|\n",
      "|A2PD27UKAD3Q00|B00005ML71|    2.0|\n",
      "| AKSFZ4G1AXYFC|B000068NSX|    4.0|\n",
      "| A67OJZLHBBUQ9|B000068NSX|    5.0|\n",
      "|A2EZWZ8MBEDOLN|B000068NSX|    5.0|\n",
      "|A1CL807EOUPVP1|B000068NSX|    5.0|\n",
      "+--------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings = df.select(\"reviewerID\", \"asin\", \"overall\")\n",
    "df_ratings.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making an ALS model, it needs to be clear that this version of ALS (integrated in Spark) only accepts integer values as parameters. \n",
    "Hence, we need to convert asin and reviewerID column in index form.\n",
    "\n",
    "We can do this by using the `StringIndexer` class from the `pyspark.ml.feature` module. \n",
    "This class transforms a column of string labels to a column of label indices. The indices are in `[0, numLabels)`, ordered by label frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-------+----------+----------------+\n",
      "|    reviewerID|      asin|overall|asin_index|reviewerID_index|\n",
      "+--------------+----------+-------+----------+----------------+\n",
      "|A2IBPI20UZIR0U|1384719342|    5.0|     703.0|            66.0|\n",
      "|A14VAT5EAX3D9S|1384719342|    5.0|     703.0|           266.0|\n",
      "|A195EZSQDW3E21|1384719342|    5.0|     703.0|           395.0|\n",
      "|A2C00NNG1ZQQG2|1384719342|    5.0|     703.0|          1048.0|\n",
      "| A94QU4C90B1AX|1384719342|    5.0|     703.0|          1311.0|\n",
      "|A2A039TZMZHH9Y|B00004Y2UT|    5.0|     562.0|            51.0|\n",
      "|A1UPZM995ZAH90|B00004Y2UT|    5.0|     562.0|           290.0|\n",
      "| AJNFQI3YR6XJ5|B00004Y2UT|    3.0|     562.0|           374.0|\n",
      "|A3M1PLEYNDEYO8|B00004Y2UT|    5.0|     562.0|            13.0|\n",
      "| AMNTZU1YQN1TH|B00004Y2UT|    5.0|     562.0|           183.0|\n",
      "|A2NYK9KWFMJV4Y|B00004Y2UT|    5.0|     562.0|             4.0|\n",
      "|A35QFQI0M46LWO|B00005ML71|    4.0|     704.0|           488.0|\n",
      "|A2NIT6BKW11XJQ|B00005ML71|    3.0|     704.0|           699.0|\n",
      "|A1C0O09LOLVI39|B00005ML71|    5.0|     704.0|            49.0|\n",
      "|A17SLR18TUMULM|B00005ML71|    5.0|     704.0|           594.0|\n",
      "|A2PD27UKAD3Q00|B00005ML71|    2.0|     704.0|           317.0|\n",
      "| AKSFZ4G1AXYFC|B000068NSX|    4.0|     455.0|           104.0|\n",
      "| A67OJZLHBBUQ9|B000068NSX|    5.0|     455.0|           250.0|\n",
      "|A2EZWZ8MBEDOLN|B000068NSX|    5.0|     455.0|             3.0|\n",
      "|A1CL807EOUPVP1|B000068NSX|    5.0|     455.0|            29.0|\n",
      "+--------------+----------+-------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
    "    for column in list(set(df_ratings.columns) - set([\"overall\"]))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "transformed = pipeline.fit(df_ratings).transform(df_ratings)\n",
    "transformed.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Test Dataset\n",
    "\n",
    "As usual, we want to split our model into training and test dataset. We can do this by using the `randomSplit` method of the `DataFrame` object. We can specify the ratio of the split and the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = transformed.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ALS Model\n",
    "\n",
    "Now we are ready to create our ALS model. We can do this by using the `ALS` class from the `pyspark.ml.recommendation` module. This class implements Alternating Least Squares (ALS) for collaborative filtering.\n",
    "\n",
    "We can specify the parameters of the model. We can specify the rank, the number of iterations, and the regularisation parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/24 15:50:33 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/03/24 15:50:33 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    }
   ],
   "source": [
    "als = ALS(\n",
    "    maxIter=5,\n",
    "    regParam=0.09,\n",
    "    rank=25,\n",
    "    userCol=\"reviewerID_index\",\n",
    "    itemCol=\"asin_index\",\n",
    "    ratingCol=\"overall\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    ")\n",
    "\n",
    "model = als.fit(training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "This is an intrinsic regression problem. Hence, we can use the `RegressionEvaluator` class from the `pyspark.ml.evaluation` module to evaluate our model. We can specify the metric name and the label column.\n",
    "\n",
    "We want to use RMSE (Root Mean Squared Error) as our metric. RMSE is a standard way to measure the error of a model. It is the square root of the average of the squared differences between the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=1.1572333294316728\n",
      "+--------------+----------+-------+----------+----------------+----------+\n",
      "|    reviewerID|      asin|overall|asin_index|reviewerID_index|prediction|\n",
      "+--------------+----------+-------+----------+----------------+----------+\n",
      "|A2KXINV90T91L8|B0009DXEEM|    4.0|     184.0|          1088.0| 4.8345084|\n",
      "|A3KX8SVSUCSHKU|B0010CAEFS|    2.0|     150.0|          1238.0|  4.296439|\n",
      "|A1HZRYGGNMOWRQ|B0002E2XCW|    5.0|      25.0|           623.0|  4.727309|\n",
      "|A2X2GEABQXRX7P|B0002CZVXM|    1.0|       5.0|          1127.0| 1.4671303|\n",
      "|A2X2GEABQXRX7P|B0002D0CQC|    5.0|      43.0|          1127.0| 1.5054607|\n",
      "| AD4MJT7YYVHP7|B0002D02RQ|    4.0|     176.0|           540.0| 4.1432943|\n",
      "| AV8MDYLHHTUOY|B000CD3QY2|    4.0|     339.0|           858.0| 2.5986018|\n",
      "|A1YR3RVSBZK8CW|B000CCJP4I|    3.0|     147.0|            31.0|  4.127996|\n",
      "|A1YR3RVSBZK8CW|B000KIRT74|    5.0|      92.0|            31.0|  5.051678|\n",
      "|A1YR3RVSBZK8CW|B000KITQKM|    5.0|     498.0|            31.0| 4.1883607|\n",
      "|A1YR3RVSBZK8CW|B000SJJCX4|    4.0|     168.0|            31.0| 4.5832562|\n",
      "|A1YR3RVSBZK8CW|B0015RIN6U|    5.0|      48.0|            31.0|  4.840294|\n",
      "|A2ZYE710E5YYCW|B000SJJCX4|    4.0|     168.0|          1139.0| 3.8367867|\n",
      "|A30GZDBGNP2366|B0002GLDQM|    3.0|       9.0|          1143.0|  3.883075|\n",
      "|A3QTFLU2ZWH7WS|B0006ZXFWO|    5.0|     128.0|           516.0|  3.843867|\n",
      "|A3RNEUUWTA78QR|B0002M3OVI|    4.0|      63.0|          1270.0| 3.6690419|\n",
      "| AASCUHX7YUC6M|B0002OOMW6|    5.0|     101.0|          1322.0| 4.3200245|\n",
      "| AFFH3F0W6N3MY|B0002FOBJY|    5.0|     475.0|          1339.0| 4.7732043|\n",
      "|  AIRZAEK6LLYQ|B000978D58|    5.0|      15.0|          1352.0|  3.771542|\n",
      "|A2DKLC2FJTY9OI|B0002E3B78|    1.0|     235.0|           451.0| 3.7630188|\n",
      "+--------------+----------+-------+----------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"overall\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "predictions = model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"RMSE=\" + str(rmse))\n",
    "predictions.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing Recommendations\n",
    "\n",
    "The only thing left to do is to provide recommendations to the users. We can do this by using the `recommendForAllUsers` method of the `ALSModel` object. This method returns a dataframe with a column of user recommendations for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:===============================================>     (90 + 10) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|reviewerID_index|     recommendations|\n",
      "+----------------+--------------------+\n",
      "|              12|[{829, 6.7125793}...|\n",
      "|              22|[{881, 5.3411007}...|\n",
      "|              26|[{803, 5.964078},...|\n",
      "|              27|[{829, 5.837696},...|\n",
      "|              28|[{829, 6.1754785}...|\n",
      "|              31|[{829, 5.7439876}...|\n",
      "|              34|[{829, 6.2537}, {...|\n",
      "|              44|[{460, 6.232315},...|\n",
      "|              53|[{803, 5.9448795}...|\n",
      "|              65|[{855, 5.8278794}...|\n",
      "+----------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_recs = model.recommendForAllUsers(20).show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting back to string form\n",
    "\n",
    "As seen in above print, the results are in integer form we need to convert it back to its original name. \n",
    "The code is little bit longer given so many conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 reviewerID                                    recommendations\n",
      "0     A00625243BI8W1SSZNLMD  [(B0002BACB4, 5.669826030731201), (B0002HLL8G,...\n",
      "1            A10044ECXDUVKS  [(B007J49GPK, 4.5154643058776855), (B009MIBIWK...\n",
      "2            A102MU6ZC9H1N6  [(B0002D0DWK, 5.5767669677734375), (B000RY68PA...\n",
      "3            A109JTUZXO61UY  [(B007J49GPK, 5.988430976867676), (B001C9R5P6,...\n",
      "4            A109ME7C09HM2M  [(B000RY68PA, 5.987866401672363), (B000VTPR08,...\n",
      "...                     ...                                                ...\n",
      "1424          AZJPNK73JF3XP  [(B0002D05FU, 5.394895076751709), (B0002GZ052,...\n",
      "1425          AZMHABTPXVLG3  [(B000MO2QJM, 3.2803802490234375), (B000KGYAYQ...\n",
      "1426          AZMIKIG4BB6BZ  [(B005F3H6Q8, 5.670292854309082), (B0001FTVD6,...\n",
      "1427          AZPDO6FLSMLFP  [(B005F3H6Q8, 5.349226474761963), (B001D2TPZU,...\n",
      "1428          AZVME8JMPD3F4  [(B000WN4J9S, 4.840417385101318), (B001L8KE06,...\n",
      "\n",
      "[1429 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x9/bmrt_9_11cg54rdt4kbz3g840000gn/T/ipykernel_69850/881410875.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new.loc[:, \"recommendations\"] = list(zip(new.asin, new.Rating))\n"
     ]
    }
   ],
   "source": [
    "recs = model.recommendForAllUsers(20).toPandas()\n",
    "df_recs = (\n",
    "    recs.recommendations.apply(pd.Series)\n",
    "    .merge(recs, right_index=True, left_index=True)\n",
    "    .drop([\"recommendations\"], axis=1)\n",
    "    .melt(id_vars=[\"reviewerID_index\"], value_name=\"recommendation\")\n",
    "    .drop(\"variable\", axis=1)\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "df_recs = df_recs.sort_values(\"reviewerID_index\")\n",
    "df_recs = pd.concat(\n",
    "    [df_recs[\"recommendation\"].apply(pd.Series), df_recs[\"reviewerID_index\"]], axis=1\n",
    ")\n",
    "\n",
    "df_recs.columns = [\"ProductID_index\", \"Rating\", \"UserID_index\"]\n",
    "tmp = transformed.select(\n",
    "    transformed[\"reviewerID\"],\n",
    "    transformed[\"reviewerID_index\"],\n",
    "    transformed[\"asin\"],\n",
    "    transformed[\"asin_index\"],\n",
    ")\n",
    "tmp = tmp.toPandas()\n",
    "\n",
    "dict1 = dict(zip(tmp[\"reviewerID_index\"], tmp[\"reviewerID\"]))\n",
    "dict2 = dict(zip(tmp[\"asin_index\"], tmp[\"asin\"]))\n",
    "\n",
    "df_recs_copy = df_recs.copy()\n",
    "df_recs_copy.loc[:, \"reviewerID\"] = df_recs[\"UserID_index\"].map(dict1)\n",
    "df_recs_copy.loc[:, \"asin\"] = df_recs[\"ProductID_index\"].map(dict2)\n",
    "df_recs_copy = df_recs_copy.sort_values(\"reviewerID\")\n",
    "df_recs_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new = df_recs_copy[[\"reviewerID\", \"asin\", \"Rating\"]]\n",
    "new[\"recommendations\"] = list(zip(new.asin, new.Rating))\n",
    "\n",
    "res = new[[\"reviewerID\", \"recommendations\"]]\n",
    "res_new = res[\"recommendations\"].groupby([res.reviewerID]).apply(list).reset_index()\n",
    "\n",
    "print(res_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We just made a recommendation system using PySpark. We used the ALS algorithm to make recommendations to users. We also evaluated our model using RMSE. We also provided recommendations to the users.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Try to use the `recommendForAllItems` method of the `ALSModel` object to provide recommendations to the items. What is the difference between the two methods?\n",
    "\n",
    "2. Try to implement the same recommendation system using a code made just by pandas and numpy to minimise the cost function using the Alternating Least Square algorithm. Compare the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec-sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
